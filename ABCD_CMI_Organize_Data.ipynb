{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import jive\n",
    "import nibabel as nb\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import nibabel as nb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = '/Users/lucindasisk/Box/LS_Folders/CMI_ABCD'\n",
    "subids = pd.read_csv(home + '/ABCD_CMI_subids.csv', header=None)[0]\n",
    "pheno_data = pd.read_csv(home + '/phenoData_analysis_08062019.csv', index_col='subjectkey')\n",
    "gifti_data = join(home, 'ABCD_metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in Area data\n",
    "data_dict_area=[]\n",
    "\n",
    "def load_data_area(sublist, home_path):\n",
    "    for sub in sublist:\n",
    "        #Area data - Left func\n",
    "        area_imgL = nb.load(join(gifti_data, 'area/{}.L.area.10k_fs_LR_sm_10.func.gii'.format(sub)))     \n",
    "        area_img_dataL = [x.data for x in area_imgL.darrays]\n",
    "        area_cur_dataL = np.reshape(area_img_dataL,(len(area_img_dataL[0]),len(area_img_dataL))).tolist()\n",
    "        #Area data - Right func\n",
    "        area_imgR = nb.load(join(gifti_data, 'area/{}.R.area.10k_fs_LR_sm_10.func.gii'.format(sub)))     \n",
    "        area_img_dataR = [x.data for x in area_imgR.darrays]\n",
    "        area_cur_dataR = np.reshape(area_img_dataR,(len(area_img_dataR[0]),len(area_img_dataR))).tolist()\n",
    "        \n",
    "        #Append data\n",
    "        area_data = [sub]\n",
    "        for x in range(0,len(area_cur_dataL)):\n",
    "            dataL = area_cur_dataL[x]\n",
    "            dataR = area_cur_dataR[x]\n",
    "            area_data.append(dataL)\n",
    "            area_data.append(dataR)\n",
    "            \n",
    "        data_dict_area.append(area_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Read in myelin data\n",
    "data_dict_myelin=[]\n",
    "\n",
    "def load_data_myelin(sublist, home_path):\n",
    "    for sub in sublist:\n",
    "\n",
    "        #Myelin Map data Left (2)\n",
    "        myelin_imgL2 = nb.load(join(gifti_data, 'MyelinMap/{}.L.MyelinMap.10k_fs_LR_sm_10.func.gii'.format(sub)))     \n",
    "        myelin_img_dataL2 = [x.data for x in myelin_imgL2.darrays]\n",
    "        myelin_cur_dataL2 = np.reshape(myelin_img_dataL2,(len(myelin_img_dataL2[0]),len(myelin_img_dataL2))).tolist()\n",
    "        #Myelin Map data Right(2)\n",
    "        myelin_imgR2 = nb.load(join(gifti_data, 'MyelinMap/{}.R.MyelinMap.10k_fs_LR_sm_10.func.gii'.format(sub)))     \n",
    "        myelin_img_dataR2 = [x.data for x in myelin_imgR2.darrays]\n",
    "        myelin_cur_dataR2 = np.reshape(myelin_img_dataR2,(len(myelin_img_dataR2[0]),len(myelin_img_dataR2))).tolist()\n",
    "\n",
    "        #Append data\n",
    "        myelin_data = [sub]\n",
    "        for x in range(0,len(myelin_cur_dataL2)):\n",
    "            dataL = myelin_cur_dataL2[x]\n",
    "            dataR = myelin_cur_dataR2[x]\n",
    "            myelin_data.append(dataL)\n",
    "            myelin_data.append(dataR)\n",
    "\n",
    "        data_dict_myelin.append(myelin_data)\n",
    "\n",
    "# Read in myelin data\n",
    "\n",
    "data_dict_thick=[]\n",
    "\n",
    "def load_data_thick(sublist, home_path):\n",
    "    for sub in sublist:\n",
    "\n",
    "        #Thickness data Left 2\n",
    "        thickness_imgL2 = nb.load(join(gifti_data, 'thickness/{}.L.thickness.10k_fs_LR_sm_10.shape.gii'.format(sub)))     \n",
    "        thickness_img_dataL2 = [x.data for x in thickness_imgL2.darrays]\n",
    "        thickness_cur_dataL2 = np.reshape(thickness_img_dataL2,(len(thickness_img_dataL2[0]),len(thickness_img_dataL2))).tolist()\n",
    "        #Thickness data Right 2\n",
    "        thickness_imgR2 = nb.load(join(gifti_data, 'thickness/{}.R.thickness.10k_fs_LR_sm_10.shape.gii'.format(sub)))     \n",
    "        thickness_img_dataR2 = [x.data for x in thickness_imgR2.darrays]\n",
    "        thickness_cur_dataR2 = np.reshape(thickness_img_dataR2,(len(thickness_img_dataR2[0]),len(thickness_img_dataR2))).tolist()\n",
    "\n",
    "        #Append data\n",
    "        thick_data = [sub]\n",
    "        for x in range(0,len(thickness_cur_dataL2)):\n",
    "            dataL = thickness_cur_dataL2[x]\n",
    "            dataR = thickness_cur_dataR2[x]\n",
    "            thick_data.append(dataL)\n",
    "            thick_data.append(dataR)\n",
    "\n",
    "        data_dict_thick.append(thick_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run function, read in data from all subjects\n",
    "#subids = subids[0:5]\n",
    "load_data_area(subids, home)\n",
    "load_data_myelin(subids, home)\n",
    "load_data_thick(subids, home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reshape Area\n",
    "cmi_df_area = pd.DataFrame(data_dict_area).rename(columns = {0:\"subid\",}).set_index('subid')\n",
    "# Rename columns automatically\n",
    "num_cols = len(cmi_df_area.columns)\n",
    "left_cols_end = int(num_cols/2)\n",
    "left_cols = range(1,left_cols_end+1)\n",
    "right_cols = range(left_cols_end + 1, num_cols+1)\n",
    "new_cols = ['area_L_' + str(i) for i in left_cols] + ['area_R_' + str(i) for i in right_cols]    \n",
    "cmi_df_area.columns = new_cols[:num_cols]\n",
    "#Rename columns\n",
    "for x in cmi_df_area.columns:\n",
    "    cmi_df_area[x] = cmi_df_area[x].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi_df_myelin = pd.DataFrame(data_dict_myelin).rename(columns = {0:\"subid\",}).set_index('subid')\n",
    "# Rename columns automatically\n",
    "num_cols = len(cmi_df_myelin.columns)\n",
    "left_cols_end = int(num_cols/2)\n",
    "left_cols = range(1,left_cols_end+1)\n",
    "right_cols = range(left_cols_end + 1, num_cols+1)\n",
    "new_cols = ['myelin_L_' + str(i) for i in left_cols] + ['myelin_R_' + str(i) for i in right_cols]    \n",
    "cmi_df_myelin.columns = new_cols[:num_cols]\n",
    "cmi_df_myelin\n",
    "#Rename columns\n",
    "for x in cmi_df_myelin.columns:\n",
    "    cmi_df_myelin[x] = cmi_df_myelin[x].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi_df_thick = pd.DataFrame(data_dict_thick).rename(columns = {0:\"subid\",}).set_index('subid')\n",
    "# Rename columns automatically\n",
    "num_cols = len(cmi_df_thick.columns)\n",
    "left_cols_end = int(num_cols/2)\n",
    "left_cols = range(1,left_cols_end+1)\n",
    "right_cols = range(left_cols_end + 1, num_cols+1)\n",
    "new_cols = ['thickness_L_' + str(i) for i in left_cols] + ['thickness_R_' + str(i) for i in right_cols]    \n",
    "cmi_df_thick.columns = new_cols[:num_cols]\n",
    "#Rename columns\n",
    "for x in cmi_df_thick.columns:\n",
    "    cmi_df_thick[x] = cmi_df_thick[x].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.merge(cmi_df_area, cmi_df_myelin, left_index = True, right_index = True, how='outer')\n",
    "m2 =  pd.merge(m1, cmi_df_thick, left_index = True, right_index = True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_area = cmi_df_area.iloc[0:35,0:30]\n",
    "mini_myelin = cmi_df_myelin.iloc[0:35,0:30]\n",
    "mini_thickness = cmi_df_thick.iloc[0:35,0:30]\n",
    "\n",
    "mini_area.to_csv(join(home + '/Mini_Area_Meas_1.10.19.csv'))\n",
    "mini_myelin.to_csv(join(home + '/Mini_Myelin_Meas_1.10.19.csv'))\n",
    "mini_thickness.to_csv(join(home + '/Mini_Thick_Meas_1.10.19.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pheno_data = pheno_data.reset_index().rename(columns = {'subjectkey':'subjectid'}).set_index('subjectid')     \n",
    "#combined = pd.merge(pheno_data, m2, left_index=True, right_index=True, how='outer')\n",
    "m2.to_csv(join(home + '/CMI_Collab_Brain_Measures_1.4.19.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
